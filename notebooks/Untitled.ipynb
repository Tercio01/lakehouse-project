{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20b909b-f828-40c8-b9cf-5a39c0265ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delta-spark==2.2.0\n",
      "  Downloading delta_spark-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pyspark<3.4.0,>=3.3.0 (from delta-spark==2.2.0)\n",
      "  Downloading pyspark-3.3.4.tar.gz (281.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m921.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark==2.2.0) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark==2.2.0) (3.17.0)\n",
      "Collecting py4j==0.10.9.5 (from pyspark<3.4.0,>=3.3.0->delta-spark==2.2.0)\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading delta_spark-2.2.0-py3-none-any.whl (20 kB)\n",
      "Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.4-py2.py3-none-any.whl size=281945740 sha256=cfbf28bf0f7a6ee37e41f93e2964a75718c0edfd184ceec6ffdf21ba90ecaf03\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a5/72/4b/16f4dac805dc367788b299db21fc03b3a26d396d883d29c454\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark, delta-spark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.5.0\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed delta-spark-2.2.0 py4j-0.10.9.5 pyspark-3.3.4\n",
      "✅ Spark Session criada com sucesso!\n",
      "✅ Orders.csv lido! Registros: 5000\n",
      "+--------+-----------+----------+--------+------------+-------------------+------------+--------------+\n",
      "|order_id|customer_id|product_id|quantity|order_amount|         order_date|order_status|payment_method|\n",
      "+--------+-----------+----------+--------+------------+-------------------+------------+--------------+\n",
      "|       1|        185|        86|       7|      303.98|2025-08-30 19:07:06|   completed|        paypal|\n",
      "|       2|         96|        22|       6|      563.95|2025-08-24 10:35:00|     pending|        paypal|\n",
      "|       3|         28|        45|       5|      650.59|2025-08-27 22:58:38|     shipped| bank_transfer|\n",
      "|       4|         90|        77|       1|      117.23|2025-09-12 06:14:33|   cancelled|        paypal|\n",
      "|       5|        115|        91|       9|      493.62|2025-09-09 17:54:57|   completed|   credit_card|\n",
      "+--------+-----------+----------+--------+------------+-------------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- order_amount: string (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install delta-spark==2.2.0\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Teste Inicial\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.2.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark Session criada com sucesso!\")\n",
    "# Testar leitura de um arquivo CSV\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"../data/bronze/orders.csv\")\n",
    "print(f\"✅ Orders.csv lido! Registros: {df.count()}\")\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d57db1b-97c6-4fc8-8fe1-cfbcfcb509c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório atual: /home/jovyan/work\n",
      "\n",
      "Conteúdo do diretório atual:\n",
      "['Untitled.ipynb', '01_bronze_to_silver.ipynb', '.ipynb_checkpoints']\n",
      "\n",
      "Conteúdo da pasta data:\n",
      "['bronze', 'silver']\n",
      "\n",
      "Conteúdo da pasta bronze:\n",
      "['orders.csv', 'orders.parquet', 'products.csv', 'customers.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Diretório atual:\", os.getcwd())\n",
    "print(\"\\nConteúdo do diretório atual:\")\n",
    "print(os.listdir('.'))\n",
    "\n",
    "print(\"\\nConteúdo da pasta data:\")\n",
    "print(os.listdir('../data/'))\n",
    "\n",
    "print(\"\\nConteúdo da pasta bronze:\")\n",
    "print(os.listdir('../data/bronze/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc9a57-b884-4104-96da-e24ba25e916f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
